{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the test script for the final submission \n",
    "# No external library other than numpy is allowed \n",
    "\n",
    "# sys is only used to point to the correct folder\n",
    "import sys\n",
    "sys.path.insert(0, 'project1/scripts')\n",
    "\n",
    "# import all the functions from the helper module \n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from proj1_plot_helpers import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import, fill in missing values with average, and perform data preprocessing \n",
    "y, inputs, ids = load_clean_csv(\"train.csv\", False, missing_val=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_regression(inputs, y):\n",
    "    queue = list(range(inputs.shape[1]))\n",
    "    selected = []\n",
    "    feats = []\n",
    "    current_score, best_score = 10.0e8, 10.0e8\n",
    "    while any(queue) and current_score == best_score:\n",
    "        scores_candidates = []\n",
    "        for candidate in queue:\n",
    "            feats = selected + [candidate]\n",
    "            poly_basis = build_poly(inputs[:, feats], 1)\n",
    "            _, score = least_squares(y, poly_basis)\n",
    "            scores_candidates.append((score, candidate))\n",
    "\n",
    "        scores_candidates.sort(reverse = True)\n",
    "        best_score, best_candidate = scores_candidates.pop()\n",
    "        if current_score > best_score:\n",
    "            queue.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_score\n",
    "    feats = selected\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-13f5570bf16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Takes only the 10 best features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepwise_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-83d42118729b>\u001b[0m in \u001b[0;36mstepwise_regression\u001b[0;34m(inputs, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselected\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mpoly_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_basis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mscores_candidates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml_project1/project1/scripts/proj1_utils.py\u001b[0m in \u001b[0;36mbuild_poly\u001b[0;34m(x, degree)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdeg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Takes only the 10 best features\n",
    "feature_list = stepwise_regression(inputs,y)[:10]\n",
    "feature_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Obtain features by finding correlation coefficients\n",
    "# coef_vec = pairwise_correlation(y, inputs)\n",
    "# pairwise_correlation_plot(coef_vec)\n",
    "\n",
    "# feature_threshold = 0.1 \n",
    "# feature_list = feature_select(coef_vec, feature_threshold)\n",
    "# corr_matrix = correlation_matrix(inputs, feature_list)\n",
    "# # print(\"feature list before removing the duplicates\", feature_list)\n",
    "# # feature_correlation_plot(corr_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove from feature list features with correlation coef higher than threhold\n",
    "# duplicate_threshold = 0.8\n",
    "\n",
    "# feature_list = feature_extract(feature_list, corr_matrix, duplicate_threshold)\n",
    "# corr_matrix = correlation_matrix(inputs, feature_list)\n",
    "# # print(\"feature list after removing the duplicates\", feature_list)\n",
    "# # feature_correlation_plot(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "def build_poly_plus(x, degree):\n",
    "    \"\"\"\n",
    "    Builds polynomial basis function of a certain degree combining all features.\n",
    "    \"\"\"\n",
    "    poly = np.ones((len(x), 1))\n",
    "\n",
    "    for deg in range(1, degree+1):\n",
    "        if deg == 1:\n",
    "            poly = np.c_[poly, x]\n",
    "        else:\n",
    "            for i in it.combinations_with_replacement(range(x.shape[1]),deg):\n",
    "                poly = np.c_[poly, np.prod(x[:,i],1)]\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = inputs[:, feature_list]\n",
    "degree = 3\n",
    "k_fold = 4\n",
    "\n",
    "tx = build_poly_plus(x, degree)\n",
    "print(tx.shape)\n",
    "lambdas = np.logspace(-5, 0, 30)\n",
    "\n",
    "# some dummy values, just to make sure the functions are properly called \n",
    "gammas = np.logspace(-3, 0, 20)\n",
    "init_w = np.zeros(tx.shape[1])\n",
    "max_it = 10\n",
    "\n",
    "opt_lambda, rmse_tr, rmse_te = find_desired_var(lambdas, y, tx, k_fold, ridge_regression)\n",
    "print(\"ridge regression done. opt_lambda is\", opt_lambda)\n",
    "opt_gamma_1, rmse_tr1, rmse_te1 = find_desired_var(gammas, y, tx, k_fold, logistic_regression, init_w, max_it)\n",
    "print(\"logistic regression done. opt_gamma is\", opt_gamma_1)\n",
    "opt_gamma_2, rmse_tr2, rmse_te2 = find_desired_var(gammas, y, tx, k_fold, least_squares_GD, init_w, max_it)\n",
    "print(\"least squares GD done. opt_gamma is\", opt_gamma_2)\n",
    "opt_gamma_3, rmse_tr3, rmse_te3 = find_desired_var(gammas, y, tx, k_fold, least_squares_SGD, init_w, max_it)\n",
    "print(\"least squares SGD done. opt_gamma is\", opt_gamma_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(opt_lambda)\n",
    "cross_validation_plot(lambdas, rmse_tr, rmse_te)\n",
    "cross_validation_plot(gammas, rmse_tr1, rmse_te1)\n",
    "cross_validation_plot(gammas, rmse_tr2, rmse_te2)\n",
    "cross_validation_plot(gammas, rmse_tr3, rmse_te3)\n",
    "#plt.savefig(\"Figures/fig_ridge_train_test_error.eps\",format = \"eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train, y_train, tx_test, y_test = split_data(tx, y, 0.5)\n",
    "\n",
    "# weights, mse = ridge_regression(y_train, tx_train, opt_lambda)\n",
    "\n",
    "#zt Update find_weight parameters. Please see the following cases \n",
    "# weights, mse = find_weight(y, tx, k_indices, opt_lambda, k_fold, degree)\n",
    "\n",
    "# dummy variables. Just to make sure the functions are properly called \n",
    "init_w = np.zeros(tx_train.shape[1])\n",
    "max_it = 10\n",
    "gamma = 0.1\n",
    "\n",
    "weights, mse = find_weight(y, tx, k_fold, least_squares)\n",
    "print(\"least squares done\")\n",
    "w1, mse1 = find_weight(y, tx, k_fold, least_squares_GD, init_w, max_it, gamma)\n",
    "print(\"least squares GD done\")\n",
    "w2, mse2 = find_weight(y, tx, k_fold, least_squares_SGD, init_w, max_it, gamma )\n",
    "print(\"least squares SGD done\")\n",
    "w3, mse3 = find_weight(y, tx, k_fold, ridge_regression, opt_lambda)\n",
    "print(\"ridge regression done\")\n",
    "w4, mse4 = find_weight(y, tx, k_fold, logistic_regression, init_w, max_it, gamma)\n",
    "print(\"logistic regression done\")\n",
    "# print(weights.shape)\n",
    "\n",
    "y_pred = predict_labels(weights, tx_test)\n",
    "\n",
    "compute_score(y_test, y_pred)\n",
    "\n",
    "rmse_train = np.sqrt(2*compute_mse(y_train, tx_train, weights))\n",
    "rmse_test = np.sqrt(2*compute_mse(y_test, tx_test, weights))\n",
    "print(\"Train RMSE:\", rmse_train, \", Test RMSE:\", rmse_test)\n",
    "\n",
    "\n",
    "# ignore: \n",
    "# Total correct: 25127.0 \n",
    "# Total incorrect: 8930.0 \n",
    "# Correct percentage: 73.77925242975012 %\n",
    "# Train RMSE: 0.9343418873952883 , Test RMSE: 0.9337667902727746\n",
    "\n",
    "# median: \n",
    "# Total correct: 95019.0 \n",
    "# Total incorrect: 29981.0 \n",
    "# Correct percentage: 76.01520000000001 %\n",
    "# Train RMSE: 0.9228025288225072 , Test RMSE: 0.9226877174336481\n",
    "\n",
    "# Average performs the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, inputs_test, ids_test = load_clean_csv('test.csv', False, \"avg\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_test = build_poly_plus(inputs_test[:,feature_list], degree)\n",
    "y_pred = predict_labels(weights, tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_csv_submission(ids_test, y_pred, \"prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
